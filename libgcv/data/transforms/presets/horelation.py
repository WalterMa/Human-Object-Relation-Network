"""Transforms for Human-object Relation Network."""
from __future__ import absolute_import
import mxnet as mx
from mxnet.gluon import data as gdata
from .. import bbox as tbbox
from .. import image as timage


class HORelationDefaultTrainTransform(object):
    """Default RODet train transform.

    Parameters
    ----------
    short : int, default is 600
        Resize image shorter side to ``short``.
    max_size : int, default is 1000
        Make sure image longer side is smaller than ``max_size``.
    mean : array-like of size 3
        Mean pixel values to be subtracted from image tensor. Default is [0.485, 0.456, 0.406].
    std : array-like of size 3
        Standard deviation to be divided from image. Default is [0.229, 0.224, 0.225].

    """
    def __init__(self, short=600, max_size=1000,
                 mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),
                 brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2):
        self._mean = mean
        self._std = std
        self._short = short
        self._max_size = max_size
        self._color_jitter = gdata.vision.transforms.RandomColorJitter(
            brightness=brightness, contrast=contrast, saturation=saturation, hue=hue)

    def __call__(self, src, label, box):
        """Apply transform to validation image/label."""
        img = src
        bbox = label
        objbox = box

        # # random crop
        # h, w, _ = img.shape
        # bbox, crop = tbbox.random_crop_with_constraints(bbox, (w, h))
        # x0, y0, w, h = crop
        # img = mx.image.fixed_crop(src, x0, y0, w, h)

        # resize shorter side but keep in max_size
        h, w, _ = img.shape
        img = timage.resize_short_within(img, self._short, self._max_size, interp=1)
        bbox = tbbox.resize(bbox, (w, h), (img.shape[1], img.shape[0]))
        objbox = tbbox.resize(objbox, (w, h), (img.shape[1], img.shape[0]))

        # color jitter
        # img = self._color_jitter(img)

        # random horizontal flip
        h, w, _ = img.shape
        img, flips = timage.random_flip(img, px=0.5)
        bbox = tbbox.flip(bbox, (w, h), flip_x=flips[0])

        img = mx.nd.image.to_tensor(img)
        img = mx.nd.image.normalize(img, mean=self._mean, std=self._std)
        return img, bbox.astype('float32'), objbox.astype('float32')


class HORelationDefaultValTransform(object):
    """Default RODet validation transform.

    Parameters
    ----------
    short : int, default is 600
        Resize image shorter side to ``short``.
    max_size : int, default is 1000
        Make sure image longer side is smaller than ``max_size``.
    mean : array-like of size 3
        Mean pixel values to be subtracted from image tensor. Default is [0.485, 0.456, 0.406].
    std : array-like of size 3
        Standard deviation to be divided from image. Default is [0.229, 0.224, 0.225].

    """
    def __init__(self, short=600, max_size=1000,
                 mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):
        self._mean = mean
        self._std = std
        self._short = short
        self._max_size = max_size

    def __call__(self, src, label, box):
        """Apply transform to validation image/label."""
        objbox = box
        # resize shorter side but keep in max_size
        h, w, _ = src.shape
        img = timage.resize_short_within(src, self._short, self._max_size, interp=1)
        # no scaling ground-truth, return image scaling ratio instead
        bbox = tbbox.resize(label, (w, h), (img.shape[1], img.shape[0]))
        objbox = tbbox.resize(objbox, (w, h), (img.shape[1], img.shape[0]))

        img = mx.nd.image.to_tensor(img)
        img = mx.nd.image.normalize(img, mean=self._mean, std=self._std)
        return img, bbox.astype('float32'), objbox.astype('float32')


class HORelationDefaultVisTransform(object):
    """Default RODet Visualization transform.

    Parameters
    ----------
    short : int, default is 600
        Resize image shorter side to ``short``.
    max_size : int, default is 1000
        Make sure image longer side is smaller than ``max_size``.
    mean : array-like of size 3
        Mean pixel values to be subtracted from image tensor. Default is [0.485, 0.456, 0.406].
    std : array-like of size 3
        Standard deviation to be divided from image. Default is [0.229, 0.224, 0.225].

    """
    def __init__(self, short=600, max_size=1000,
                 mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):
        self._mean = mean
        self._std = std
        self._short = short
        self._max_size = max_size

    def __call__(self, src, label, box):
        """Apply transform to validation image/label."""
        objbox = box
        # resize shorter side but keep in max_size
        h, w, _ = src.shape
        img = timage.resize_short_within(src, self._short, self._max_size, interp=1)
        ori_img = img.astype('uint8')
        # no scaling ground-truth, return image scaling ratio instead
        bbox = tbbox.resize(label, (w, h), (img.shape[1], img.shape[0]))
        objbox = tbbox.resize(objbox, (w, h), (img.shape[1], img.shape[0]))

        img = mx.nd.image.to_tensor(img)
        img = mx.nd.image.normalize(img, mean=self._mean, std=self._std)
        return img, bbox.astype('float32'), objbox.astype('float32'), ori_img
